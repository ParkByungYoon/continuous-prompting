{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from model.continuous_prompt import ContinuousPromptingLLM\n",
    "from model.recsys_encoder import RecsysContinuousPromptModel\n",
    "from model.projection import BasicProjection\n",
    "from dataset import RecsysDataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "from util import convert_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE='test'\n",
    "TASK='recommendation'\n",
    "MODEL_NAME = 'light-gcn'\n",
    "LLM_DIR = \"/SSL_NAS/bonbak/model/models--yanolja--EEVE-Korean-Instruct-2.8B-v1.0/snapshots/482db2d0ba911253d09342c34d0e42ac871bfea3\"\n",
    "SAVE_DIR=f'/home/bonbak/continuous-prompting/output/{TASK}'\n",
    "TASKS_DIR = f'/home/bonbak/continuous-prompting/task/{TASK}'\n",
    "DEVICE='cuda:2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = RecsysDataset(f\"{TASKS_DIR}/{MODE}.jsonl\", f\"{TASKS_DIR}/edge.csv\")\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "num_users, num_items = len(test_dataset.user_mapping), len(test_dataset.item_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_prompt_model = RecsysContinuousPromptModel(num_users,num_items,f'{TASKS_DIR}/train_edge_index.pt')\n",
    "projection_module = BasicProjection(continuous_prompt_model.model.embedding_dim)\n",
    "\n",
    "model = ContinuousPromptingLLM(\n",
    "    LLM_DIR,\n",
    "    continuous_prompt_model, \n",
    "    continuous_prompt_model.model.embedding_dim\n",
    ")\n",
    "\n",
    "model.continuous_prompt_model.load_state_dict(torch.load(f'{SAVE_DIR}/model/{MODEL_NAME}-encoder.bin'))\n",
    "model.projection_module.load_state_dict(torch.load(f'{SAVE_DIR}/model/{MODEL_NAME}-projection.bin'))\n",
    "\n",
    "continuous_prompt_model.to(DEVICE)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = []\n",
    "label = []\n",
    "\n",
    "idx = 0\n",
    "for input_text, continuous_prompt_input, answer_list in tqdm(test_dataloader):\n",
    "    with torch.no_grad():\n",
    "        inputs_embeds, attention_mask = model.make_input_embed(input_text, continuous_prompt_input, embedding_first=True)\n",
    "        output = model.llm_model.generate(inputs_embeds=inputs_embeds, attention_mask=attention_mask, pad_token_id=model.llm_tokenizer.eos_token_id, max_new_tokens=1)\n",
    "        pred.append(model.llm_tokenizer.batch_decode(output, skip_special_tokens=True)[0])\n",
    "        label.append(answer_list[0])\n",
    "    if idx == 500:\n",
    "        break\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def convert_answer(answer):\n",
    "    converted = []\n",
    "    for a in answer:\n",
    "        a = a.strip()\n",
    "        if a == '예':\n",
    "            converted.append(1)\n",
    "        elif a == '아니':\n",
    "            converted.append(0)\n",
    "        else:\n",
    "            converted.append(-1)\n",
    "    return np.array(converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = convert_answer(pred)\n",
    "y_true = convert_answer(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(accuracy)\n",
    "print(f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "starlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
