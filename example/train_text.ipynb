{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from model.continuous_prompt import ContinuousPromptingLLM\n",
    "from model.text_encoder import TextContinuousPromptModel\n",
    "from model.projection import BasicProjection\n",
    "\n",
    "from dataset import Dataset\n",
    "from util import plot_and_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE='train'\n",
    "TASK='cycle_check'\n",
    "MODEL_NAME = 'bert-cls2'\n",
    "SAVE_DIR=f'/home/bonbak/GraphToken/output/{TASK}'\n",
    "TASKS_DIR = f'/home/bonbak/GraphToken/task/{TASK}'\n",
    "DEVICE='cuda:3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G describes a graph among nodes 0, 1, 2, 3, 4, and 5.\n",
      "The edges in G are: (0, 1) (0, 2) (0, 3) (0, 5) (1, 3) (1, 4) (1, 5) (2, 3) (2, 4) (2, 5) (4, 5).\n",
      "You must answer with \"Yes\" or \"No\" under the question.\n",
      "Q: Is there a cycle in this graph?\n",
      "A: \n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(f\"{TASKS_DIR}/{MODE}.jsonl\")\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "print('\\n'.join((train_dataset.data[0]['node_information'], train_dataset.data[0]['edge_information'], train_dataset.data[0]['question'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67dbffd1ff344b928938dadf28ae91fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "continuous_prompt_model = TextContinuousPromptModel('distilbert/distilbert-base-uncased')\n",
    "projection_module = BasicProjection(continuous_prompt_model.model.config.hidden_size)\n",
    "\n",
    "model = ContinuousPromptingLLM(\n",
    "    \"google/gemma-2b-it\",\n",
    "    continuous_prompt_model, \n",
    "    continuous_prompt_model.model.config.hidden_size\n",
    ")\n",
    "\n",
    "continuous_prompt_model.to(DEVICE)\n",
    "model.to(DEVICE)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.projection_module.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.continuous_prompt_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must answer with \"Yes\" or \"No\" under the question.\n",
      "Q: Is there a cycle in this graph?\n",
      "A:  Yes<eos>\n",
      "step 80 | cur_loss : 0.4104 | min_loss : 0.4104 \n",
      "step 160 | cur_loss : 0.4532 | min_loss : 0.4104 \n",
      "You must answer with \"Yes\" or \"No\" under the question.\n",
      "Q: Is there a cycle in this graph?\n",
      "A:  Yes<eos>\n",
      "step 240 | cur_loss : 0.3008 | min_loss : 0.3008 \n",
      "step 320 | cur_loss : 0.3792 | min_loss : 0.3008 \n",
      "step 400 | cur_loss : 0.4208 | min_loss : 0.3008 \n",
      "You must answer with \"Yes\" or \"No\" under the question.\n",
      "Q: Is there a cycle in this graph?\n",
      "A:  No<eos>\n",
      "step 480 | cur_loss : 0.2759 | min_loss : 0.2759 \n",
      "step 560 | cur_loss : 0.3799 | min_loss : 0.2759 \n",
      "step 640 | cur_loss : 0.3599 | min_loss : 0.2759 \n",
      "You must answer with \"Yes\" or \"No\" under the question.\n",
      "Q: Is there a cycle in this graph?\n",
      "A:  Yes<eos>\n",
      "step 720 | cur_loss : 0.2396 | min_loss : 0.2396 \n",
      "step 800 | cur_loss : 0.3051 | min_loss : 0.2396 \n",
      "step 880 | cur_loss : 0.3257 | min_loss : 0.2396 \n",
      "step 960 | cur_loss : 0.3596 | min_loss : 0.2396 \n",
      "You must answer with \"Yes\" or \"No\" under the question.\n",
      "Q: Is there a cycle in this graph?\n",
      "A:  No<eos>\n",
      "step 1040 | cur_loss : 0.2102 | min_loss : 0.2102 \n",
      "You must answer with \"Yes\" or \"No\" under the question.\n",
      "Q: Is there a cycle in this graph?\n",
      "A:  Yes<eos>\n",
      "step 1120 | cur_loss : 0.1791 | min_loss : 0.1791 \n",
      "step 1200 | cur_loss : 0.3128 | min_loss : 0.1791 \n",
      "step 1280 | cur_loss : 0.1974 | min_loss : 0.1791 \n",
      "step 1360 | cur_loss : 0.3987 | min_loss : 0.1791 \n",
      "step 1440 | cur_loss : 0.2520 | min_loss : 0.1791 \n",
      "step 1520 | cur_loss : 0.2664 | min_loss : 0.1791 \n",
      "step 1600 | cur_loss : 0.2220 | min_loss : 0.1791 \n",
      "step 1680 | cur_loss : 0.3889 | min_loss : 0.1791 \n",
      "step 1760 | cur_loss : 0.3265 | min_loss : 0.1791 \n",
      "step 1840 | cur_loss : 0.1887 | min_loss : 0.1791 \n",
      "step 1920 | cur_loss : 0.2443 | min_loss : 0.1791 \n",
      "You must answer with \"Yes\" or \"No\" under the question.\n",
      "Q: Is there a cycle in this graph?\n",
      "A:  Yes<eos>\n",
      "step 2000 | cur_loss : 0.1406 | min_loss : 0.1406 \n",
      "You must answer with \"Yes\" or \"No\" under the question.\n",
      "Q: Is there a cycle in this graph?\n",
      "A:  No<eos>\n",
      "step 2080 | cur_loss : 0.1207 | min_loss : 0.1207 \n",
      "step 2160 | cur_loss : 0.2065 | min_loss : 0.1207 \n",
      "step 2240 | cur_loss : 0.1315 | min_loss : 0.1207 \n",
      "step 2320 | cur_loss : 0.3314 | min_loss : 0.1207 \n",
      "step 2400 | cur_loss : 0.1444 | min_loss : 0.1207 \n",
      "step 2480 | cur_loss : 0.2334 | min_loss : 0.1207 \n",
      "step 2560 | cur_loss : 0.2370 | min_loss : 0.1207 \n",
      "step 2640 | cur_loss : 0.2483 | min_loss : 0.1207 \n",
      "step 2720 | cur_loss : 0.3444 | min_loss : 0.1207 \n",
      "step 2800 | cur_loss : 0.1707 | min_loss : 0.1207 \n",
      "step 2880 | cur_loss : 0.3446 | min_loss : 0.1207 \n",
      "step 2960 | cur_loss : 0.1843 | min_loss : 0.1207 \n",
      "step 3040 | cur_loss : 0.1233 | min_loss : 0.1207 \n",
      "You must answer with \"Yes\" or \"No\" under the question.\n",
      "Q: Is there a cycle in this graph?\n",
      "A:  Yes<eos>\n",
      "step 3120 | cur_loss : 0.0914 | min_loss : 0.0914 \n",
      "step 3200 | cur_loss : 0.2103 | min_loss : 0.0914 \n",
      "step 3280 | cur_loss : 0.1559 | min_loss : 0.0914 \n",
      "step 3360 | cur_loss : 0.1458 | min_loss : 0.0914 \n",
      "step 3440 | cur_loss : 0.4019 | min_loss : 0.0914 \n",
      "step 3520 | cur_loss : 0.2607 | min_loss : 0.0914 \n",
      "step 3600 | cur_loss : 0.1144 | min_loss : 0.0914 \n",
      "step 3680 | cur_loss : 0.2282 | min_loss : 0.0914 \n",
      "step 3760 | cur_loss : 0.2298 | min_loss : 0.0914 \n",
      "step 3840 | cur_loss : 0.1566 | min_loss : 0.0914 \n",
      "step 3920 | cur_loss : 0.2102 | min_loss : 0.0914 \n",
      "step 4000 | cur_loss : 0.4506 | min_loss : 0.0914 \n",
      "step 4080 | cur_loss : 0.1522 | min_loss : 0.0914 \n",
      "step 4160 | cur_loss : 0.2534 | min_loss : 0.0914 \n",
      "You must answer with \"Yes\" or \"No\" under the question.\n",
      "Q: Is there a cycle in this graph?\n",
      "A:  Yes<eos>\n",
      "step 4240 | cur_loss : 0.0728 | min_loss : 0.0728 \n",
      "You must answer with \"Yes\" or \"No\" under the question.\n",
      "Q: Is there a cycle in this graph?\n",
      "A:  Yes<eos>\n",
      "step 4320 | cur_loss : 0.0625 | min_loss : 0.0625 \n",
      "step 4400 | cur_loss : 0.1084 | min_loss : 0.0625 \n",
      "step 4480 | cur_loss : 0.1064 | min_loss : 0.0625 \n",
      "step 4560 | cur_loss : 0.2660 | min_loss : 0.0625 \n",
      "step 4640 | cur_loss : 0.0857 | min_loss : 0.0625 \n",
      "step 4720 | cur_loss : 0.2662 | min_loss : 0.0625 \n",
      "step 4800 | cur_loss : 0.2812 | min_loss : 0.0625 \n",
      "step 4880 | cur_loss : 0.1327 | min_loss : 0.0625 \n",
      "step 4960 | cur_loss : 0.0845 | min_loss : 0.0625 \n",
      "step 5040 | cur_loss : 0.0730 | min_loss : 0.0625 \n",
      "step 5120 | cur_loss : 0.1073 | min_loss : 0.0625 \n",
      "step 5200 | cur_loss : 0.0856 | min_loss : 0.0625 \n",
      "step 5280 | cur_loss : 0.2081 | min_loss : 0.0625 \n",
      "step 5360 | cur_loss : 0.0646 | min_loss : 0.0625 \n",
      "step 5440 | cur_loss : 0.1537 | min_loss : 0.0625 \n",
      "step 5520 | cur_loss : 0.1649 | min_loss : 0.0625 \n",
      "step 5600 | cur_loss : 0.1984 | min_loss : 0.0625 \n",
      "step 5680 | cur_loss : 0.1626 | min_loss : 0.0625 \n",
      "step 5760 | cur_loss : 0.1030 | min_loss : 0.0625 \n",
      "step 5840 | cur_loss : 0.1153 | min_loss : 0.0625 \n",
      "step 5920 | cur_loss : 0.1782 | min_loss : 0.0625 \n",
      "You must answer with \"Yes\" or \"No\" under the question.\n",
      "Q: Is there a cycle in this graph?\n",
      "A:  Yes<eos>\n",
      "step 6000 | cur_loss : 0.0501 | min_loss : 0.0501 \n",
      "step 6080 | cur_loss : 0.0543 | min_loss : 0.0501 \n",
      "step 6160 | cur_loss : 0.1236 | min_loss : 0.0501 \n",
      "step 6240 | cur_loss : 0.0948 | min_loss : 0.0501 \n",
      "step 6320 | cur_loss : 0.3243 | min_loss : 0.0501 \n",
      "You must answer with \"Yes\" or \"No\" under the question.\n",
      "Q: Is there a cycle in this graph?\n",
      "A:  Yes<eos>\n",
      "step 6400 | cur_loss : 0.0246 | min_loss : 0.0246 \n",
      "step 6480 | cur_loss : 0.3771 | min_loss : 0.0246 \n",
      "step 6560 | cur_loss : 0.2380 | min_loss : 0.0246 \n",
      "step 6640 | cur_loss : 0.1111 | min_loss : 0.0246 \n",
      "step 6720 | cur_loss : 0.2447 | min_loss : 0.0246 \n",
      "step 6800 | cur_loss : 0.0901 | min_loss : 0.0246 \n",
      "step 6880 | cur_loss : 0.1600 | min_loss : 0.0246 \n",
      "step 6960 | cur_loss : 0.2479 | min_loss : 0.0246 \n",
      "step 7040 | cur_loss : 0.3113 | min_loss : 0.0246 \n",
      "step 7120 | cur_loss : 0.0348 | min_loss : 0.0246 \n",
      "step 7200 | cur_loss : 0.0275 | min_loss : 0.0246 \n",
      "step 7280 | cur_loss : 0.2824 | min_loss : 0.0246 \n",
      "step 7360 | cur_loss : 0.0762 | min_loss : 0.0246 \n",
      "step 7440 | cur_loss : 0.1305 | min_loss : 0.0246 \n",
      "step 7520 | cur_loss : 0.2026 | min_loss : 0.0246 \n",
      "You must answer with \"Yes\" or \"No\" under the question.\n",
      "Q: Is there a cycle in this graph?\n",
      "A:  Yes<eos>\n",
      "step 7600 | cur_loss : 0.0126 | min_loss : 0.0126 \n",
      "step 7680 | cur_loss : 0.0764 | min_loss : 0.0126 \n",
      "step 7760 | cur_loss : 0.2992 | min_loss : 0.0126 \n",
      "step 7840 | cur_loss : 0.1107 | min_loss : 0.0126 \n",
      "step 7920 | cur_loss : 0.3552 | min_loss : 0.0126 \n",
      "step 8000 | cur_loss : 0.1167 | min_loss : 0.0126 \n",
      "step 8080 | cur_loss : 0.1701 | min_loss : 0.0126 \n",
      "step 8160 | cur_loss : 0.0519 | min_loss : 0.0126 \n",
      "step 8240 | cur_loss : 0.1277 | min_loss : 0.0126 \n",
      "step 8320 | cur_loss : 0.0901 | min_loss : 0.0126 \n",
      "step 8400 | cur_loss : 0.1047 | min_loss : 0.0126 \n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "c = 0\n",
    "loss_log_list = []\n",
    "min_loss = 1000000\n",
    "accumulate_step = 8\n",
    "\n",
    "def mean(lst):\n",
    "    return sum(lst)/len(lst)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for input_text, continuous_prompt_input, answer_list in train_dataloader:\n",
    "        inputs_embeds, attention_mask, labels = model.make_seq2seq_input_label(input_text,continuous_prompt_input,answer_list, embedding_first=True)\n",
    "\n",
    "        generated_output = model.llm_model.forward(\n",
    "                    inputs_embeds=inputs_embeds,\n",
    "                    attention_mask = attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "        generated_output.loss.backward()\n",
    "        \n",
    "        if c % accumulate_step == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        loss_log_list.append(generated_output.loss.item())\n",
    "        \n",
    "        if c % 80 == 0 and c!=0:\n",
    "            cur_loss = mean(loss_log_list[-accumulate_step:])\n",
    "            if min_loss > cur_loss:\n",
    "                model.eval()\n",
    "                model.to('cpu')\n",
    "                min_loss = cur_loss\n",
    "                torch.save(model.projection_module.state_dict(), f'{SAVE_DIR}/model/{MODEL_NAME}-projection.bin')\n",
    "                torch.save(model.continuous_prompt_model.state_dict(), f'{SAVE_DIR}/model/{MODEL_NAME}-encoder.bin')\n",
    "\n",
    "                inputs_embeds, attention_mask = model.make_input_embed(input_text,continuous_prompt_input, embedding_first=True)\n",
    "                output = model.llm_model.generate(inputs_embeds=inputs_embeds, attention_mask=attention_mask, max_new_tokens=4)\n",
    "                print(input_text[0], model.llm_tokenizer.decode(output[0]))\n",
    "                plot_and_save(loss_log_list, f'{SAVE_DIR}/loss/{MODEL_NAME}.png')\n",
    "\n",
    "                model.train()\n",
    "                model.to(DEVICE)\n",
    "\n",
    "            print(f'step {c} | cur_loss : {cur_loss:.4f} | min_loss : {min_loss:.4f} ')\n",
    "        c+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "starlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
